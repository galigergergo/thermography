{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of Test Data on all Models\n",
    "You have to run this script if you want to reproduce some Figures from the paper.\n",
    "Inference will be done on all unseen test data on all models (80 in total), generating 800,000 output images as a result.\n",
    "\n",
    "\n",
    "\n",
    "## Checking GPU Availability\n",
    "First, let's see if we have a GPU available. It is highly recommended to utilize a GPU, although it is also possible to run this experiment on the CPU at a much slower rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda\n"
     ]
    }
   ],
   "source": [
    "from experiment import *\n",
    "from experiment_config import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Current device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact Hybrid Model Inference on real-world Data - FISTA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(os.getcwd(), 'data', 'realworld', 'fistanet', 'RotatedData_filt_2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\galiger.gergo\\\\Desktop\\\\ThermUNet-master\\\\data\\\\hybrid\\\\models\\\\cmp\\\\80k\\\\only_square_admm\\\\2020-4-25_13-32-31.889297\\\\models\\\\best_model.pth']\n",
      "using cuda:0 for inference...\n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\only_square_admm\\2020-4-25_13-32-31.889297\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\realworld\\fistanet\\RotatedData_filt_2000\\Deg_0 \n"
     ]
    }
   ],
   "source": [
    "cmp_hybrid_models = get_cmp_hybrid_models()\n",
    "print(cmp_hybrid_models)\n",
    "inference_realworld(input_dir, cmp_hybrid_models[0], device, \"Deg_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Hybrid Model Inference on real-world Data - FISTA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\galiger.gergo\\\\Desktop\\\\ThermUNet-master\\\\data\\\\hybrid\\\\models\\\\lrg\\\\80k\\\\only_square_admm\\\\models\\\\best_model.pth']\n",
      "using cuda:0 for inference...\n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\only_square_admm\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\realworld\\fistanet\\RotatedData_filt_2000\\Deg_10 \n"
     ]
    }
   ],
   "source": [
    "lrg_hybrid_models = get_lrg_hybrid_models()\n",
    "print(lrg_hybrid_models)\n",
    "inference_realworld(input_dir, lrg_hybrid_models[0], device, \"Deg_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Hybrid Model Inference on all Test Data - ADMM Abel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(os.getcwd(), 'data', 'hybrid', 'fistanet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "lrg_hybrid_models = get_lrg_hybrid_models()\n",
    "print(lrg_hybrid_models)\n",
    "multi_inference_test(input_dir, lrg_hybrid_models, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact Hybrid Model Inference on all Test Data - ADMM Abel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\galiger.gergo\\\\Desktop\\\\ThermUNet-master\\\\data\\\\hybrid\\\\models\\\\cmp\\\\80k\\\\more_shapes_admm\\\\2022-12-23_23-22-19.858192\\\\models\\\\best_model.pth']\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\n",
      "using cuda:0 for inference...\n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_70 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_60 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_50 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_40 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_30 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_20 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_10 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_0 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_-10 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\fistanet\\SNR_-20 \n"
     ]
    }
   ],
   "source": [
    "cmp_hybrid_models = get_cmp_hybrid_models()\n",
    "print(cmp_hybrid_models)\n",
    "print(input_dir)\n",
    "multi_inference_test(input_dir, cmp_hybrid_models, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Hybrid Model Inference on all Test Data - ADMM Curvelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(os.getcwd(), 'data', 'hybrid', 'admm_curvelet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\galiger.gergo\\\\Desktop\\\\ThermUNet-master\\\\data\\\\hybrid\\\\models\\\\lrg\\\\80k\\\\2020-4-25_15-5-29.503889\\\\models\\\\best_model.pth']\n",
      "using cuda:0 for inference...\n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_70 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_60 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_50 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_40 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_30 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_20 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_10 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_0 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_-10 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\lrg\\80k\\2020-4-25_15-5-29.503889\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_-20 \n"
     ]
    }
   ],
   "source": [
    "lrg_hybrid_models = get_lrg_hybrid_models()\n",
    "print(lrg_hybrid_models)\n",
    "multi_inference_test(input_dir, lrg_hybrid_models, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact Hybrid Model Inference on all Test Data - ADMM Curvelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 for inference...\n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_70 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_60 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_50 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_40 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_30 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_20 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_10 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_0 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_-10 \n",
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\models\\cmp\\80k\\more_shapes_admm\\2022-12-23_23-22-19.858192\\models\\best_model\\C\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\admm_curvelet\\SNR_-20 \n"
     ]
    }
   ],
   "source": [
    "cmp_hybrid_models = get_cmp_hybrid_models()\n",
    "multi_inference_test(input_dir, cmp_hybrid_models, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Hybrid Model Inference on all Test Data - FISTA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(os.getcwd(), 'data', 'hybrid', 'fistanet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 for inference...\n"
     ]
    }
   ],
   "source": [
    "lrg_hybrid_models = get_lrg_hybrid_models()\n",
    "multi_inference_test(input_dir, lrg_hybrid_models, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact Hybrid Model Inference on all Test Data - FISTA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 for inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cmp_hybrid_models \u001b[38;5;241m=\u001b[39m get_cmp_hybrid_models()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmulti_inference_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmp_hybrid_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ThermUNet-master\\experiment.py:359\u001b[0m, in \u001b[0;36mmulti_inference_test\u001b[1;34m(input_dir, model_files, device, verbosity)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmulti_inference_test\u001b[39m(input_dir, model_files, device, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_file \u001b[38;5;129;01min\u001b[39;00m model_files:\n\u001b[1;32m--> 359\u001b[0m         \u001b[43minference_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ThermUNet-master\\experiment.py:353\u001b[0m, in \u001b[0;36minference_test\u001b[1;34m(input_dir, model_file, device, verbosity)\u001b[0m\n\u001b[0;32m    349\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_inference_test_data(input_dir, normalizer)\n\u001b[0;32m    351\u001b[0m prefix_path \u001b[38;5;241m=\u001b[39m model_file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 353\u001b[0m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ThermUNet-master\\experiment.py:298\u001b[0m, in \u001b[0;36minference\u001b[1;34m(model, dataset, result_prefix, verbosity)\u001b[0m\n\u001b[0;32m    294\u001b[0m image_files \u001b[38;5;241m=\u001b[39m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_file\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    296\u001b[0m X \u001b[38;5;241m=\u001b[39m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# [N, 1, H, W]\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [N, nb_classes, H, W]\u001b[39;00m\n\u001b[0;32m    300\u001b[0m prediction_sigmoid \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(prediction\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m    301\u001b[0m output \u001b[38;5;241m=\u001b[39m prediction_sigmoid\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\.conda\\envs\\thermcvenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\ThermUNet-master\\thermunet.py:81\u001b[0m, in \u001b[0;36mThermUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, up \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_path):\n\u001b[0;32m     79\u001b[0m     x \u001b[38;5;241m=\u001b[39m up(x, blocks[\u001b[38;5;241m-\u001b[39mi \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\thermcvenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\thermcvenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\thermcvenv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cmp_hybrid_models = get_cmp_hybrid_models()\n",
    "multi_inference_test(input_dir, cmp_hybrid_models, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large End-to-End Model Inference on all Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n"
     ]
    }
   ],
   "source": [
    "input_dir = os.path.join(os.getcwd(), 'data', 'end2end', 'test')\n",
    "\n",
    "lrg_e2e_models = get_lrg_e2e_models()\n",
    "multi_inference_test(input_dir, lrg_e2e_models, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact End-to-End Model Inference on all Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n",
      "using cuda:0 for inference...\n"
     ]
    }
   ],
   "source": [
    "cmp_e2e_models = get_cmp_e2e_models()\n",
    "multi_inference_test(input_dir, cmp_e2e_models, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
