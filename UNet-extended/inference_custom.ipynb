{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of Test Data with a Custom Model\n",
    "In this script, you can take a model that you have trained yourself, and do inference on the unseen test data.\n",
    "That is, all SNR conditions, each comprising 1,000 samples, summing up to 10,000 resulting images.\n",
    "\n",
    "\n",
    "## Checking GPU Availability\n",
    "First, let's see if we have a GPU available. It is highly recommended to utilize a GPU, although it is also possible to run this experiment on the CPU at a much slower rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from experiment import inference_test\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Current device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(os.getcwd(), 'data', 'hybrid', 'test')\n",
    "\n",
    "model_file = r'.\\data\\hybrid\\train\\2020-11-10_12-51-39.620050\\models\\best_model.pth'\n",
    "inference_test(input_dir, model_file, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
