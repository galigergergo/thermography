{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Hybrid Models\n",
    "\n",
    "## Checking GPU Availability\n",
    "First, let's see if we have a GPU available. It is highly recommended to utilize a GPU, although it is also possible to run this experiment on the CPU at a much slower rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda\n"
     ]
    }
   ],
   "source": [
    "from experiment import *\n",
    "from data_utils import load_hybrid_data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Current device: \" + str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Training Data\n",
    "Here, we define the paths to the images and their corresponding masks (targets).\n",
    "The values for normalization are pre-computed from the training data in order to save time.\n",
    "In case you want to reproduce all results from the paper, you need to run this notebook several times with different amount of training data. Remember that the actual number is 10-fold higher than what the start/stop inidices suggest, since we have every sample in 10 versions with different SNRs.\n",
    "\n",
    "Because we wanted to compare the effect of using an increasing number of samples for training, we kept the validation data always the same for a fair and meaningful comparison of the results. Notice, (contrary to the training data) we don't apply any augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 10000\n",
      "Number of validation samples: 0\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(os.getcwd(), 'data', 'hybrid', 'train')\n",
    "mask_dir = os.path.join(os.getcwd(), 'data', 'masks', 'train')\n",
    "\n",
    "\n",
    "# hybrid\n",
    "normalizer = {\n",
    "        'norm_mean': [101],\n",
    "        'norm_std': [26],\n",
    "        }\n",
    "\n",
    "start = 0\n",
    "stop = 1000\n",
    "#stop = 2000\n",
    "#stop = 4000\n",
    "#stop = 8000\n",
    "train_dataset = load_hybrid_data(train_dir, mask_dir, start, stop, normalizer, augment=True)\n",
    "\n",
    "# this subset is always reserved as the validation set, regardless of the number of training samples\n",
    "start = 9000\n",
    "stop = 10000\n",
    "val_dataset = load_hybrid_data(train_dir, mask_dir, start, stop, normalizer)\n",
    "\n",
    "print('Number of training samples: ' + str(len(train_dataset)))\n",
    "print('Number of validation samples: ' + str(len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Architecture\n",
    "Here, we create the actual architecture of our network, and set it up to be used in the previously determined device (cpu or cuda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give create the compact architecture...\n",
    "# model = get_cmp_thermunet().to(torch.device(device))\n",
    "\n",
    "# ...or you could use the more complex architecture\n",
    "model = get_lrg_thermunet().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Architecture\n",
    "We can have a look at the architecture and check for instance, if the number of parameters is what we expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─ModuleList: 1-1                        --\n",
      "|    └─UNetConvBlock: 2-1                --\n",
      "|    |    └─Sequential: 3-1              2,480\n",
      "|    └─UNetConvBlock: 2-2                --\n",
      "|    |    └─Sequential: 3-2              13,888\n",
      "|    └─UNetConvBlock: 2-3                --\n",
      "|    |    └─Sequential: 3-3              55,424\n",
      "|    └─UNetConvBlock: 2-4                --\n",
      "|    |    └─Sequential: 3-4              221,440\n",
      "|    └─UNetConvBlock: 2-5                --\n",
      "|    |    └─Sequential: 3-5              885,248\n",
      "├─ModuleList: 1-2                        --\n",
      "|    └─UNetUpBlock: 2-6                  --\n",
      "|    |    └─Sequential: 3-6              32,896\n",
      "|    |    └─UNetConvBlock: 3-7           442,624\n",
      "|    └─UNetUpBlock: 2-7                  --\n",
      "|    |    └─Sequential: 3-8              8,256\n",
      "|    |    └─UNetConvBlock: 3-9           110,720\n",
      "|    └─UNetUpBlock: 2-8                  --\n",
      "|    |    └─Sequential: 3-10             2,080\n",
      "|    |    └─UNetConvBlock: 3-11          27,712\n",
      "|    └─UNetUpBlock: 2-9                  --\n",
      "|    |    └─Sequential: 3-12             528\n",
      "|    |    └─UNetConvBlock: 3-13          6,944\n",
      "├─Conv2d: 1-3                            17\n",
      "=================================================================\n",
      "Total params: 1,810,257\n",
      "Trainable params: 1,810,257\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─ModuleList: 1-1                        --\n",
       "|    └─UNetConvBlock: 2-1                --\n",
       "|    |    └─Sequential: 3-1              2,480\n",
       "|    └─UNetConvBlock: 2-2                --\n",
       "|    |    └─Sequential: 3-2              13,888\n",
       "|    └─UNetConvBlock: 2-3                --\n",
       "|    |    └─Sequential: 3-3              55,424\n",
       "|    └─UNetConvBlock: 2-4                --\n",
       "|    |    └─Sequential: 3-4              221,440\n",
       "|    └─UNetConvBlock: 2-5                --\n",
       "|    |    └─Sequential: 3-5              885,248\n",
       "├─ModuleList: 1-2                        --\n",
       "|    └─UNetUpBlock: 2-6                  --\n",
       "|    |    └─Sequential: 3-6              32,896\n",
       "|    |    └─UNetConvBlock: 3-7           442,624\n",
       "|    └─UNetUpBlock: 2-7                  --\n",
       "|    |    └─Sequential: 3-8              8,256\n",
       "|    |    └─UNetConvBlock: 3-9           110,720\n",
       "|    └─UNetUpBlock: 2-8                  --\n",
       "|    |    └─Sequential: 3-10             2,080\n",
       "|    |    └─UNetConvBlock: 3-11          27,712\n",
       "|    └─UNetUpBlock: 2-9                  --\n",
       "|    |    └─Sequential: 3-12             528\n",
       "|    |    └─UNetConvBlock: 3-13          6,944\n",
       "├─Conv2d: 1-3                            17\n",
       "=================================================================\n",
       "Total params: 1,810,257\n",
       "Trainable params: 1,810,257\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if next(model.parameters()).is_cuda else 'cpu')\n",
    "\n",
    "summary(model, input_size=(1, 64, 256), device=str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Finally, we can start the training procedure.\n",
    "The folder names to store the results are automatically generated and based on a timestamp.\n",
    "They are always a subfolder of the training data folder.\n",
    "\n",
    "In case you want to observe some random output samples during training, you can set the visualization_lvl to either 1 (plot validation data output samples) or 2 (plot validation and training data output samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\data\\hybrid\\train\\2022-12-24_12-26-53.827116\\models \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n",
      "C:\\Users\\galiger.gergo\\Desktop\\ThermUNet-master\\experiment.py:52: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  assert mean is not -1 and std is not -1, 'Normalize transform not detected!'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      2\u001b[0m visualization_lvl \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualization_lvl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining finished...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\ThermUNet-master\\experiment.py:105\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataset, val_dataset, epochs, visualization_lvl)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# make data iterable\u001b[39;00m\n\u001b[0;32m    104\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m get_dataloader(train_dataset)\n\u001b[1;32m--> 105\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# used to keep track of the best model so far\u001b[39;00m\n\u001b[0;32m    108\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mInf\n",
      "File \u001b[1;32m~\\Desktop\\ThermUNet-master\\experiment.py:63\u001b[0m, in \u001b[0;36mget_dataloader\u001b[1;34m(dataset, batch_size, shuffle, pin_memory, num_workers)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataloader\u001b[39m(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 63\u001b[0m     data_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_loader\n",
      "File \u001b[1;32m~\\.conda\\envs\\thermcvenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 344\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\thermcvenv\\lib\\site-packages\\torch\\utils\\data\\sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "visualization_lvl = 1\n",
    "\n",
    "train(model, train_dataset, val_dataset, epochs, visualization_lvl)\n",
    "\n",
    "print(\"training finished...\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
